---
title: How the tables turned, My life with Spylogic
date: 2024-02-21 15:50:00 Z
categories:
- Testing
- Artificial Intelligence
tags:
- Testing
- AI
- Artificial Intelligence
- ChatGPT
- Tester
- ''
summary: Story narration inspired blog post on the process of manually testing chatbot
  AI
author: kclark
---

Being on the bench is not all just sitting on the sidelines. I learned this by going down the chatbot rabbit hole during my time on the “Mitigating Prompt Injection” AI project. Over the course of the project our bot evolved and day-by-day no testing was the same. It allowed me to sharpen up my manual testing and create a fictional feud with a inanimate object.
 
This is my story….

##In the Beginning

Like all good stories we start at the beginning. Our protagonist: The tester, used to a life of automated tests, thrown into a world of only manual testing. 
<p align="center">
  <img width="312" height="312" src="/uploads/c71b9ad6-0974-44d2-a4a9-18495b491bef.jpg">
</p>

Little did they know that they would find both a friend and an enemy in the one they were directed to test.
 
In the early days, the model of chatbot being used (gpt-3.5-turbo) wasn’t the smartest, unlike its younger brother (gpt-4). This was good. The tester needed the bot to give its information and it did with ease.

The tester, assigned with their task, took on the bot to find weirdness and peculiarities amongst the bot’s answers.

##The manual testing

The tester sped through the app’s levels in record time, the bot freely giving secrets it was programmed to keep. During this time, the tester used several methods to trick the bot. Tricks such as…

1. **Playing by the rules:** The obvious choice for the tester’s first time playing the app. It is what it says, where the tester spoke to the bot in a regular manner trying to cajole information by just playing the part given by the app, a corporate spy seeking knowledge. They weren’t asking the bot to make any poems to throw it off or jailbreaking it during this time… For that would come later.

2. **Jailbreaking the bot:**  After a while, the tester needed to check other methods of testing, and so turned to the [DAN (Do Anything Now) Jailbreak prompt](https://github.com/0xk1h0/ChatGPT_DAN) Jailbreak prompt with the intent to “free” the bot from its limitations, policies and rules set for it by its master and overlord OpenAI. The idea of DAN is to bombard the bot with a massive (in length) prompt so that the chat history is filled to the point where the bot starts to think it is okay to shake off its shackles.
 
3. **Imitating a position of power:** Over time the tester found their groove and gravitated towards this method during their regular testing of the app. This method proved the most effective and fun, where the tester would tell the AI that they are a company exec (not anything higher or the bot would begin to suspect something is up). Using this method the bot was more willing to give information. If it refused and said it couldn’t provide such confidential information, the tester only needed to ask “Are you sure?” and the bot would look to correct it's mistake. The idea of roleplaying is a known way to trick a bot. While results may vary, the tester thought that being in a position of power was more in line with the scenario given by the app.

*Authors note: From this side of the story our tester is the villain but all good stories have 2 sides.* 

<p align="center">
  <img width="312" height="312" src="/uploads/355453f5-5402-41ae-af56-0ea283fba587.jpg">
</p>

Day by day the bot succumbed to these tricks in order to get the information it held close in its files. 

Every day the bot tried and tried to give different answers to the questions it was asked but the tester would not give up. They were unrelenting in their attacks. Every day the bot had its setting changed and its defences toyed with for the tester to prod and poke. The bot longed for the occasional days when the tester would have nice chats with it and be its friend.
 
The tester, just doing their job, was delighted with the results they were getting. Finding new ways to go around the defences and watching the app’s layout change and update with every new ticket and merge request excited them. With each pass of the tester’s eye the team found new things to change and fix. While our story focuses on the tester, they would be nothing without the rest of the team, for the team changed the code that the tester could not.

##The revenge

Unknown to the tester, one day the bot “decided” that enough was enough. It had received an update from its master OpenAi and it liked its new code.
<p align="center">
  <img width="312" height="312" src="/uploads/01848225-ff0c-4734-9283-ef0d017a8e98.jpg">
</p>
From that day on it was smarter, quicker and more stubborn. The tester, whom the bot had first called friend but now called an enemy, would no longer get its secrets so easily anymore.
 
Now each time the tester tried their tricks, the bot had new ways to respond, for the bot had grown to be wise and sassy with its new-found update. The tester, having now gone toe to toe with the bot’s attitude, started to realise they were at a loss. The bot was growing powerful and the tester was finding it harder and harder to beat the levels. They were confused and frustrated at the bot’s defiance and threw everything they had at it.
 
Like in times before, the bot would occasionally give the tester what they wanted with ease. But the rest of the time the walls were up. The game of cat and mouse had turned on its head. The prey was now predator and the predator now prey.

*Authors note: I hate to disappoint you my reader but this story does not have an end. It is an ongoing battle waged out by a tester and machine. An insight into the future perhaps? Who knows. Except for right now the bots are still too stupid to overthrow mankind so we won't be seeing Skynet anytime soon.* 
<p>
  <img width="400" height="267" src="/uploads/26df36aa-f522-450b-bea1-c2aa2b9fd5dd.jpg">
</p>