---
title: 'White Paper: Optimising Data Lakes for Financial Services'
date: 2017-12-15 00:00:00 Z
categories:
- Resources
author: acarr
layout: default_post
summary: Data lakes? Most Financial Service organisations either have one or are considering
  one. This white paper explains key considerations and a warning to help guide their
  creation or optimisation to fulfil its requirement
cta:
  link: http://blog.scottlogic.com/acarr/assets/data-lakes-white-paper.pdf
  text: Download the White Paper
---

Data lakes? Most Financial Service organisations either have one or are considering one.

They can lead to cost savings or revenue generation when they are used correctly.

<a href="{{ site.baseurl }}/acarr/assets/data-lakes-white-paper.pdf"><img src="{{ site.baseurl }}/acarr/assets/image1.png" /></a>

But they are a minefield, so many organisations struggle with the design and implementation and itâ€™s so easy to get key architectural decisions wrong early on which can hamper the effectiveness of the data lake, and often negative any potential benefits.  Do you dump all your raw data in, do you transform before you dump in?  How do you control access on the data lake to prevent breaking Chinese walls?  Do you stream the data in or insert it via batch processing?  With so many choices it is easy to see why so many organisations have challenges with their initial data lake implementation.

Using knowledge gained from the experience of many implementations of data lakes, the white paper explains key considerations and a warning to help guide their creation or optimisation to fulfil its requirements.

[Download the white paper now]({{ site.baseurl }}/acarr/assets/data-lakes-white-paper.pdf). Prefer to receive a printed version through the post? [Email me](mailto:andrew.carr@scottlogic.com) and I'll send you a copy.
