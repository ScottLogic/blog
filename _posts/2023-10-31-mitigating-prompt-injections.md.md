---
title: Mitigating prompt injections on Generative AI systems
date: 2023-10-31 00:00:00 Z
categories:
- Tech
- Artificial Intelligence
summary: We demonstrate our web app used for experimenting with different types of
  prompt injection attacks and mitigations on LLMs and how easy it can be to hack
  GPT through malicious prompts.
author: dhinrichs
video_url: https://www.youtube.com/embed/TD3RG9YPKEY
short-author-aside: true
layout: video_post
---

We demonstrate our web app used for experimenting with different types of prompt injection attacks and mitigations on LLMs and how easy it can be to hack GPT through malicious prompts.
